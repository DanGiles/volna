//
// auto-generated by op2.py
//

//user function
__device__
inline void computeGradient_gpu(const float *center,
                            const float *neighbour1, 
                            const float *neighbour2,
                            const float *neighbour3,
                            const float *cellCenter,
                            const float *nb1Center,
                            const float *nb2Center,
                            const float *nb3Center,
                            float *out) //OP_WRITE
{
        if( cellCenter[0] != nb3Center[0]){

        float total;
        float dh[3], weights[3], Rhs[2];
        float Gram[2][2], inverse[2][2], delta[3][2];
        float x = cellCenter[0];
        float y = cellCenter[1];
	
        delta[0][0] =  (nb1Center[0] - x);
        delta[0][1] =  (nb1Center[1] - y);

        delta[1][0] =  (nb2Center[0] - x);
        delta[1][1] =  (nb2Center[1] - y);

        delta[2][0] =  (nb3Center[0] - x);
        delta[2][1] =  (nb3Center[0] - y);

        weights[0] = sqrt(delta[0][0] * delta[0][0] + delta[0][1] * delta[0][1]);
        weights[1] = sqrt(delta[1][0] * delta[1][0] + delta[1][1] * delta[1][1]);
	weights[2] = sqrt(delta[2][0] * delta[2][0] + delta[2][1] * delta[2][1]);

        total = sqrt(weights[0]*weights[0]) + sqrt(weights[1]*weights[1]) + sqrt(weights[2]*weights[2]);
     
	weights[0] /= total;
	weights[1] /= total;
	weights[2] /= total;

        delta[0][0] *= weights[0];
        delta[0][1] *= weights[0];

        delta[1][0] *= weights[1];
        delta[1][1] *= weights[1];

        delta[2][0] *= weights[2];
        delta[2][1] *= weights[2];

        Gram[0][0] = ((delta[0][0]*delta[0][0]) + (delta[1][0] *delta[1][0]) + (delta[2][0] *delta[2][0]));
        Gram[0][1] = ((delta[0][0]*delta[0][1]) + (delta[1][0] *delta[1][1]) + (delta[2][0] *delta[2][1]));
        Gram[1][0] = ((delta[0][0]*delta[0][1]) + (delta[1][0] *delta[1][1]) + (delta[2][0] *delta[2][1]));
        Gram[1][1] = ((delta[0][1]*delta[0][1]) + (delta[1][1] *delta[1][1]) + (delta[2][1] *delta[2][1]));

        float det = 1.0 / (Gram[0][0]*Gram[1][1] - Gram[0][1]*Gram[1][0]);
        inverse[0][0] = det * Gram[1][1];
        inverse[0][1] = det * (- Gram[0][1]);
        inverse[1][0] = det * (-Gram[1][0]);
        inverse[1][1] = det * Gram[0][0];
        int i ;

        for (i=0; i<4; i++){

            dh[0] = neighbour1[i] - center[i];
            dh[1] = neighbour2[i] - center[i];
            dh[2] = neighbour3[i] - center[i];
            dh[0] *= weights[0];
            dh[1] *= weights[1];
            dh[2] *= weights[2];
            Rhs[0] = (delta[0][0]*dh[0]) + (delta[1][0]*dh[1]) + (delta[2][0]*dh[2]);
            Rhs[1] = (delta[0][1]*dh[0]) + (delta[1][1]*dh[1]) + (delta[2][1]*dh[2]); 
            
            Rhs[0] = (inverse[0][0] * dh[0]) + (inverse[0][1] * dh[1]);
            Rhs[1] = (inverse[1][0] * dh[0]) + (inverse[1][1] * dh[1]);
            
            out[2*i] = Rhs[0];
	    out[2*i + 1] = Rhs[1];
        };
        }else {
        out[0] = 0;
        out[1] = 0;
        out[2] = 0;
        out[3] = 0;
        out[4] = 0;
        out[5] = 0;
        out[6] = 0;
        out[7] = 0;
        }
}


// CUDA kernel function
__global__ void op_cuda_computeGradient(
  const float *__restrict ind_arg0,
  const float *__restrict ind_arg1,
  const int *__restrict opDat1Map,
  const float *__restrict arg0,
  const float *__restrict arg4,
  float *arg8,
  int    block_offset,
  int   *blkmap,
  int   *offset,
  int   *nelems,
  int   *ncolors,
  int   *colors,
  int   nblocks,
  int   set_size) {

  __shared__ int    nelem, offset_b;

  extern __shared__ char shared[];

  if (blockIdx.x+blockIdx.y*gridDim.x >= nblocks) {
    return;
  }
  if (threadIdx.x==0) {

    //get sizes and shift pointers and direct-mapped data

    int blockId = blkmap[blockIdx.x + blockIdx.y*gridDim.x  + block_offset];

    nelem    = nelems[blockId];
    offset_b = offset[blockId];

  }
  __syncthreads(); // make sure all of above completed
  for ( int n=threadIdx.x; n<nelem; n+=blockDim.x ){
    int map1idx;
    int map2idx;
    int map3idx;
    map1idx = opDat1Map[n + offset_b + set_size * 0];
    map2idx = opDat1Map[n + offset_b + set_size * 1];
    map3idx = opDat1Map[n + offset_b + set_size * 2];

    //user-supplied kernel call
    computeGradient_gpu(arg0+(n+offset_b)*4,
                    ind_arg0+map1idx*4,
                    ind_arg0+map2idx*4,
                    ind_arg0+map3idx*4,
                    arg4+(n+offset_b)*2,
                    ind_arg1+map1idx*2,
                    ind_arg1+map2idx*2,
                    ind_arg1+map3idx*2,
                    arg8+(n+offset_b)*8);
  }
}


//GPU host stub function
void op_par_loop_computeGradient_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8){

  int nargs = 9;
  op_arg args[9];

  args[0] = arg0;
  args[1] = arg1;
  args[2] = arg2;
  args[3] = arg3;
  args[4] = arg4;
  args[5] = arg5;
  args[6] = arg6;
  args[7] = arg7;
  args[8] = arg8;

  // initialise timers
  double cpu_t1, cpu_t2, wall_t1, wall_t2;
  op_timing_realloc(3);
  op_timers_core(&cpu_t1, &wall_t1);
  OP_kernels[3].name      = name;
  OP_kernels[3].count    += 1;
  if (OP_kernels[3].count==1) op_register_strides();


  int    ninds   = 2;
  int    inds[9] = {-1,0,0,0,-1,1,1,1,-1};

  if (OP_diags>2) {
    printf(" kernel routine with indirection: computeGradient\n");
  }

  //get plan
  #ifdef OP_PART_SIZE_3
    int part_size = OP_PART_SIZE_3;
  #else
    int part_size = OP_part_size;
  #endif

  int set_size = op_mpi_halo_exchanges_cuda(set, nargs, args);
  if (set->size > 0) {

    op_plan *Plan = op_plan_get(name,set,part_size,nargs,args,ninds,inds);

    //execute plan

    int block_offset = 0;
    for ( int col=0; col<Plan->ncolors; col++ ){
      if (col==Plan->ncolors_core) {
        op_mpi_wait_all_cuda(nargs, args);
      }
      #ifdef OP_BLOCK_SIZE_3
      int nthread = OP_BLOCK_SIZE_3;
      #else
      int nthread = OP_block_size;
      #endif

      dim3 nblocks = dim3(Plan->ncolblk[col] >= (1<<16) ? 65535 : Plan->ncolblk[col],
      Plan->ncolblk[col] >= (1<<16) ? (Plan->ncolblk[col]-1)/65535+1: 1, 1);
      if (Plan->ncolblk[col] > 0) {
        op_cuda_computeGradient<<<nblocks,nthread>>>(
        (float *)arg1.data_d,
        (float *)arg5.data_d,
        arg1.map_data_d,
        (float*)arg0.data_d,
        (float*)arg4.data_d,
        (float*)arg8.data_d,
        block_offset,
        Plan->blkmap,
        Plan->offset,
        Plan->nelems,
        Plan->nthrcol,
        Plan->thrcol,
        Plan->ncolblk[col],
        set->size+set->exec_size);

      }
      block_offset += Plan->ncolblk[col];
    }
    OP_kernels[3].transfer  += Plan->transfer;
    OP_kernels[3].transfer2 += Plan->transfer2;
  }
  op_mpi_set_dirtybit_cuda(nargs, args);
  cutilSafeCall(cudaDeviceSynchronize());
  //update kernel record
  op_timers_core(&cpu_t2, &wall_t2);
  OP_kernels[3].time     += wall_t2 - wall_t1;
}

void op_par_loop_computeGradient_cpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8);


//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_computeGradient(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8){

  if (OP_hybrid_gpu) {
    op_par_loop_computeGradient_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8);

    }else{
    op_par_loop_computeGradient_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8);

  }
}
#else
void op_par_loop_computeGradient(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8){

  op_par_loop_computeGradient_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4,
    arg5,
    arg6,
    arg7,
    arg8);

  }
#endif //OP_HYBRID_GPU
